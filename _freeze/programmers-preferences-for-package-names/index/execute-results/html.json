{
  "hash": "2999e0138cba33c87c15ba1eae1c11ab",
  "result": {
    "markdown": "---\ntitle: Programmers' preferences for package names\ncategories: [analysis, python, julia, rust]\nkeywords: python, julia, rust, R\nsummary: I was curious how package names were chosen in various language ecosystems.\ndate: 2022-07-29T01:47:12-0600\n---\n\nAre there trends in choosing package names in various programming ecosystems?\nDo package authors choose names for their packages that are [alliterated](https://en.wikipedia.org/wiki/Alliteration) with the name of the programming language?\nLet's venture to find out.\n\nFirst let's install a couple of useful packages.\n\n::: {.cell execution_count=2}\n``` {.julia .cell-code code-fold=\"true\"}\nusing Pkg\nPkg.activate(@__DIR__)\nPkg.add(\"Plots\")\nPkg.add(\"StatsPlots\")\nPkg.add(\"DataStructures\")\nPkg.add(\"HTTP\")\nPkg.add(\"JSON3\")\nPkg.add(\"DataFrames\")\nPkg.add(\"CSV\")\nPkg.add(\"CodecZlib\")\nPkg.add(\"Tar\")\n```\n:::\n\n\nWe can \"bucket\" the package names by their starting letter and count the number of packages in each bucket, i.e. a frequency plot.\n\n::: {.cell execution_count=3}\n``` {.julia .cell-code code-fold=\"true\"}\nusing Plots\nusing DataStructures\nusing HTTP\nusing Markdown\n\nfunction get_buckets(items)\n  buckets = DefaultDict(0)\n  items = strip.(items)\n  for item in items\n    buckets[lowercase(first(item))] += 1\n  end\n  total = sum(values(buckets))\n  for (k, v) in buckets\n    buckets[k] = v / total\n  end\n  (buckets, total)\nend\n\nfunction frequency_plot((buckets, total); lang, kind=\"packages\")\n  fig_size = (800, 600)\n  names = [k for k in sort(collect(keys(buckets)))]\n  colors = DefaultDict(\"grey\")\n  percent = DefaultDict(\"\")\n  starting_letter = first(lowercase(lang))\n  if kind == \"packages\"\n    colors[starting_letter] = \"orange\"\n    for (k, v) in buckets\n      p = round((buckets[k] - WORD_BUCKETS[k]) * 100, digits=1)\n      percent[k] = \"\\n($(sign(p) > 0 ? '+' : '-')$(p)%)\"\n    end\n  end\n  ax = bar([buckets[n] for n in names], xticks=(1:length(names), names), fillcolor=[colors[n] for n in names], size=(1600, 1000), legend=false, yaxis=false)\n  annotate!(1:length(names), [buckets[n] + (1 / (kind == \"packages\" ? 350 : 500)) for n in names], [(\"$(round(buckets[n] * 100, digits=1))%$(percent[n])\", 8) for n in names])\n  title!(\"Frequency of $kind in $lang (Total: $total)\")\n\n  summary = if kind == \"packages\"\n    \"\"\"\n    The difference in percent of names of $lang packages starting with \"$starting_letter\" and words in the English language starting with \"$starting_letter\" is $(replace(strip(percent[starting_letter]), \")\" => \"\", \"(\" => \"\")).\n    \"\"\"\n  else\n    \"\"\n  end\n  (ax, summary)\nend\n\nnothing\n```\n:::\n\n\n## English\n\nFor a reference case, let's plot the distribution of words in the English language, per the list in `/usr/share/dict/words` on my MacOS 12.5.\n\n::: {.cell execution_count=4}\n``` {.julia .cell-code code-fold=\"true\"}\nwords = open(\"/usr/share/dict/words\") do f\n  readlines(f)\nend\nWORD_BUCKETS, WORD_TOTAL = get_buckets(words)\nax, summary = frequency_plot((WORD_BUCKETS, WORD_TOTAL), lang=\"/usr/share/dict/words\", kind=\"words\")\ndisplay(ax)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-4-output-1.svg){}\n:::\n:::\n\n\n## Python\n\nFor Python, we can get the list of packages on PyPi using <https://pypi.org/simple> and get the names of all packages from the links.\n\n::: {.cell execution_count=5}\n``` {.julia .cell-code code-fold=\"true\"}\nr = HTTP.get(\"https://pypi.org/simple\")\ndata = String(r.body)\nlines = strip.(split(data, \"\\n\"));\nlinks = filter(startswith(\"<a href=\\\"\"), lines); # filter all the lines that start with a link\npackages = first.(match.(r\">(.*)</a>\", links)); # get the contents of these links, using a regex match\npackages = filter(name -> isletter(first(name)), packages); # get only packages that start with a letter.\n\nPYTHON_BUCKETS, PYTHON_TOTAL = get_buckets(packages)\nax, summary = frequency_plot((PYTHON_BUCKETS, PYTHON_TOTAL), lang=\"Python\")\ndisplay(ax)\ndisplay(\"text/markdown\", summary)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-5-output-1.svg){}\n:::\n\n::: {.cell-output .cell-output-display}\nThe difference in percent of names of Python packages starting with \"p\" and words in the English language starting with \"p\" is +3.3%.\n\n:::\n:::\n\n\nPersonally, I'm surprised this difference isn't higher.\n\n## Julia\n\nWhen you install a package using Julia, it downloads a general registry into your \"home\" directory, and we can traverse that directory only one level deep to figure out all the names of the packages in the registry.\n\n::: {.cell execution_count=6}\n``` {.julia .cell-code code-fold=\"true\"}\ngeneral_folder = expanduser(\"~/.julia/registries/General\")\nfor (root, folders, files) in walkdir(general_folder)\n  for folder in folders\n    if length(folder) > 1 && length(split(replace(root, general_folder => \"\"), \"/\")) == 2 && !endswith(folder, \"_jll\")\n      push!(packages, folder)\n    end\n  end\nend\n\nJULIA_BUCKETS, JULIA_TOTAL = get_buckets(packages)\nax, summary = frequency_plot((JULIA_BUCKETS, JULIA_TOTAL), lang=\"Julia\", kind=\"packages\")\ndisplay(ax)\ndisplay(\"text/markdown\", summary)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-1.svg){}\n:::\n\n::: {.cell-output .cell-output-display}\nThe difference in percent of names of Julia packages starting with \"j\" and words in the English language starting with \"j\" is +0.9%.\n\n:::\n:::\n\n\n## Rust\n\n<https://crates.io> conveniently has a [data-access](https://crates.io/data-access) page that links to the latest dump which contains a `csv` file with the names of all the packages.\n\n::: {.cell execution_count=7}\n``` {.julia .cell-code code-fold=\"true\"}\nusing DataFrames\nusing CSV\nusing Tar\nusing CodecZlib\ntmp = tempname()\ndownload(\"https://static.crates.io/db-dump.tar.gz\", tmp)\nfolder = open(tmp) do file\n  Tar.extract(GzipDecompressorStream(file))\nend\nfilename = joinpath(folder, only(readdir(folder)), \"data/crates.csv\")\npackages = DataFrame(CSV.File(filename))[!, :name]\n\nRUST_BUCKETS, RUST_TOTAL = get_buckets(packages)\nax, summary = frequency_plot((RUST_BUCKETS, RUST_TOTAL), lang=\"Rust\")\ndisplay(ax)\ndisplay(\"text/markdown\", summary)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.svg){}\n:::\n\n::: {.cell-output .cell-output-display}\nThe difference in percent of names of Rust packages starting with \"r\" and words in the English language starting with \"r\" is +3.7%.\n\n:::\n:::\n\n\n## R\n\nFor R, similar to Python, we can parse the HTML from <https://cran.r-project.org/web/packages/available_packages_by_name.html>:\n\n::: {.cell execution_count=8}\n``` {.julia .cell-code code-fold=\"true\"}\nr = HTTP.get(\"https://cran.r-project.org/web/packages/available_packages_by_name.html\")\ndata = String(r.body)\nlines = split(data, \"\\n\")\nlines = filter(line -> startswith(line, \"<td><a href=\\\"\"), lines)\npackages = first.(match.(r\">(.*)</a>\", links))\npackages = filter(name -> isletter(first(name)), packages)\n\nR_BUCKETS, R_TOTAL = get_buckets(packages)\nax, summary = frequency_plot((R_BUCKETS, R_TOTAL), lang=\"R\")\ndisplay(ax)\ndisplay(\"text/markdown\", summary)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-8-output-1.svg){}\n:::\n\n::: {.cell-output .cell-output-display}\nThe difference in percent of names of R packages starting with \"r\" and words in the English language starting with \"r\" is --0.6%.\n\n:::\n:::\n\n\nThis is also a rather surprising result.\n\n## NPM\n\nFor NPM packages, <https://replicate.npmjs.com/_all_docs> contains a 228 MB `json` that contains all the packages.\n\n::: {.cell execution_count=9}\n``` {.julia .cell-code code-fold=\"true\"}\nusing JSON3\n\ndata = JSON3.read(read(expanduser(\"~/Downloads/_all_docs\"), String))\npackages = map(data[:rows]) do elem\n  last(split(elem[:id], \"/\"))\nend\npackages = filter(name -> isletter(first(name)), packages)\n\nNPM_BUCKETS, NPM_TOTAL = get_buckets(packages)\nax, summary = frequency_plot((NPM_BUCKETS, NPM_TOTAL), lang=\"NPM\")\ndisplay(ax)\ndisplay(\"text/markdown\", summary)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-9-output-1.svg){}\n:::\n\n::: {.cell-output .cell-output-display}\nThe difference in percent of names of NPM packages starting with \"n\" and words in the English language starting with \"n\" is +2.3%.\n\n:::\n:::\n\n\n## Comparison\n\nHere's a plot comparing the normalized values:\n\n::: {.cell execution_count=10}\n``` {.julia .cell-code code-fold=\"true\"}\nusing StatsPlots\n\ngroupedbar(repeat('a':'z', inner=6), hcat([\n    [WORD_BUCKETS[letter] for letter in 'a':'z'],\n    [PYTHON_BUCKETS[letter] for letter in 'a':'z'],\n    [JULIA_BUCKETS[letter] for letter in 'a':'z'],\n    [RUST_BUCKETS[letter] for letter in 'a':'z'],\n    [R_BUCKETS[letter] for letter in 'a':'z'],\n    [NPM_BUCKETS[letter] for letter in 'a':'z'],\n  ]...), title=\"Comparison of English words, Python, Julia, Rust, R and NPM packages\", group=repeat([\"English\", \"Python\", \"Julia\", \"Rust\", \"R\", \"NPM\"], outer=26), yaxis=false, size=(1600, 1000))\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n![](index_files/figure-html/cell-10-output-1.svg){}\n:::\n:::\n\n\n## Conclusion\n\nEven though there is a greater percentage of packages whose name starts with the same letter as the name of the programming language compared to the average distribution of words in the English language, it is not by as big a margin as I was expecting.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}
